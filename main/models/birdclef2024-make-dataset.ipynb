{"cells":[{"cell_type":"markdown","metadata":{},"source":["## 1. Import"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T02:19:47.437465Z","iopub.status.busy":"2024-06-09T02:19:47.43696Z","iopub.status.idle":"2024-06-09T02:20:56.141484Z","shell.execute_reply":"2024-06-09T02:20:56.14024Z","shell.execute_reply.started":"2024-06-09T02:19:47.437419Z"},"trusted":true},"outputs":[],"source":["# basic\n","import os\n","import gzip\n","import bz2\n","\n","# python\n","import pickle\n","import pywt\n","import librosa\n","import numpy as np\n","from pathlib import Path\n","from scipy import signal\n","from scipy import optimize\n","from time import time\n","!pip install fcwt\n","\n","# notebook\n","from IPython.display import Audio\n","import matplotlib.pyplot as plt \n","import cv2\n","\n","# PyTorch\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch import optim\n","from torch.optim import lr_scheduler\n","from torch.cuda import amp\n","import timm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T02:37:01.642137Z","iopub.status.busy":"2024-06-09T02:37:01.64109Z","iopub.status.idle":"2024-06-09T02:37:01.660994Z","shell.execute_reply":"2024-06-09T02:37:01.659743Z","shell.execute_reply.started":"2024-06-09T02:37:01.642095Z"},"trusted":true},"outputs":[],"source":["class Config:\n","    def __init__(self):\n","        # train env\n","        self.TEST_SOUNDSCAPE = Path('/kaggle/input/birdclef-2024/test_soundscapes')\n","        self.NO_SOUNDSCAPE = False\n","        \n","        # test env\n","        if 1 >= len(os.listdir(self.TEST_SOUNDSCAPE)):\n","            self.TEST_SOUNDSCAPE = Path('/kaggle/input/birdclef-2024/train_audio/asbfly')\n","            self.NO_SOUNDSCAPE = True\n","\n","    model_name = \"efficientnet_b0.ra_in1k\"  # model will be used\n","    img_size = 224                          # input size. If it's 256, input image resize to 256x256\n","    n_folds = 5                             # number of folds\n","    interpolation = cv2.INTER_AREA          # specifying method of interpolation(dfault is cv2.INTER_LINEAR)\n","    max_epoch = 9                           # number of max epoch. 1epoch means going around the training dataset.\n","#     batch_size = 32                       # train batch size. Number of samples passed to the network in one training step\n","    batch_size = 1                          # test batch size. openvino can't response flexibility to leftovers of number of batches \n","    lr = 1.0e-03                            # learning rate. determine step size when updating model's weight\n","    weight_decay = 1.0e-02                  # weight decay. Append regularization term for prevent over fitting\n","    es_patience = 5                         # Early Stopping\n","    seed = 1086                             # seed\n","    deterministic = True                    # deterministic, it returns same resurlts if the all configs are same.\n","    enable_amp = False                      # enable or disable the Automatic Mixed Precision\n","#     device = \"cuda\"                       # Device to use training. \"cuda\" is a NVIDIA GPU\n","    device = \"cpu\"                          # Device to use training. \"cpu\" is a cpu\n","    \n","    \n","    simple_training = True                  # only use few data with training, be enable in training\n","    simple_inferring = False                # only use few data with inferring\n","    n_simple = 100                          # number of data with simple training\n","    test = False                            # when inference\n","    \n","    DURATION = 5                            # length of cropped data\n","    LENGTH = DURATION\n","    \n","    MELSPEC_H = 128                         # horizontal melspectrogram resolution\n","    MELSPEC_H = 256\n","    MELSPEC_H = 128\n","    MELSPEC_H = 64\n","    \n","    TOP_DB = 100                            # maximum decibel to clip audio to\n","    MIN_RATING = 0.0                        # minimum rating\n","\n","    SR = 32000                              # sample rate\n","    audio_len = DURATION*SR\n","    \n","    N_FFT = 2048 # 1024 # 5096              # STFT parameters\n","    HOP_LENGTH = 512\n","    window = 2048\n","    fmin = 20\n","    fmax = 16000\n","    \n","#     ONLY_ONCE = True                      # train with 1 data only\n","    ONLY_ONCE = False\n","#     VIEW = True                           # whether show processed data or not\n","    VIEW = False                           \n","#     VIEW_RAW = True                       # whether show raw data or not\n","    VIEW_RAW = False\n","    \n","    \n","    # Related to faster inference \n","    INPUT_SHAPE: list[int] = [1, 1, 224, 224] \n","    DUMMY_INPUT_TENSOR: torch.Tensor = torch.randn(*INPUT_SHAPE)\n","    DUMMY_INPUT_NUMPY_FP32: np.ndarray = DUMMY_INPUT_TENSOR.numpy()\n","    DUMMY_INPUT_NUMPY_FP16: np.ndarray = DUMMY_INPUT_NUMPY_FP32.astype(np.float16)\n","    OUTPUT_DIR_ONNX: Path = Path('./model/onnx')\n","    OUTPUT_DIR_OV: Path = Path('./model/ov')\n","\n","\n","CFG = Config()"]},{"cell_type":"markdown","metadata":{},"source":["### Wavelet Transfrom"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T02:37:03.504588Z","iopub.status.busy":"2024-06-09T02:37:03.502875Z","iopub.status.idle":"2024-06-09T02:37:03.575444Z","shell.execute_reply":"2024-06-09T02:37:03.574039Z","shell.execute_reply.started":"2024-06-09T02:37:03.504531Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch import nn\n","\n","from scipy import optimize\n","from scipy.special import factorial, gamma, hermitenorm\n","from timm.models.layers import conv2d_same\n","\n","\n","\n","### from https://github.com/tomrunia/PyTorchWavelets/blob/master/wavelets_pytorch/wavelets.py\n","class Morlet(object):\n","    def __init__(self, w0=6):\n","        \"\"\"w0 is the nondimensional frequency constant. If this is\n","        set too low then the wavelet does not sample very well: a\n","        value over 5 should be ok; Terrence and Compo set it to 6.\n","        \"\"\"\n","        self.w0 = w0\n","        if w0 == 6:\n","            # value of C_d from TC98\n","            self.C_d = 0.776\n","\n","    def __call__(self, *args, **kwargs):\n","        return self.time(*args, **kwargs)\n","\n","    def time(self, t, s=1.0, complete=True):\n","        \"\"\"\n","        Complex Morlet wavelet, centred at zero.\n","        Parameters\n","        ----------\n","        t : float\n","            Time. If s is not specified, this can be used as the\n","            non-dimensional time t/s.\n","        s : float\n","            Scaling factor. Default is 1.\n","        complete : bool\n","            Whether to use the complete or the standard version.\n","        Returns\n","        -------\n","        out : complex\n","            Value of the Morlet wavelet at the given time\n","        See Also\n","        --------\n","        scipy.signal.gausspulse\n","        Notes\n","        -----\n","        The standard version::\n","            pi**-0.25 * exp(1j*w*x) * exp(-0.5*(x**2))\n","        This commonly used wavelet is often referred to simply as the\n","        Morlet wavelet.  Note that this simplified version can cause\n","        admissibility problems at low values of `w`.\n","        The complete version::\n","            pi**-0.25 * (exp(1j*w*x) - exp(-0.5*(w**2))) * exp(-0.5*(x**2))\n","        The complete version of the Morlet wavelet, with a correction\n","        term to improve admissibility. For `w` greater than 5, the\n","        correction term is negligible.\n","        Note that the energy of the return wavelet is not normalised\n","        according to `s`.\n","        The fundamental frequency of this wavelet in Hz is given\n","        by ``f = 2*s*w*r / M`` where r is the sampling rate.\n","        \"\"\"\n","        w = self.w0\n","\n","        x = t / s\n","\n","        output = np.exp(1j * w * x)\n","\n","        if complete:\n","            output -= np.exp(-0.5 * (w ** 2))\n","\n","        output *= np.exp(-0.5 * (x ** 2)) * np.pi ** (-0.25)\n","\n","        return output\n","\n","    # Fourier wavelengths\n","    def fourier_period(self, s):\n","        \"\"\"Equivalent Fourier period of Morlet\"\"\"\n","        return 4 * np.pi * s / (self.w0 + (2 + self.w0 ** 2) ** 0.5)\n","\n","    def scale_from_period(self, period):\n","        \"\"\"\n","        Compute the scale from the fourier period.\n","        Returns the scale\n","        \"\"\"\n","        # Solve 4 * np.pi * scale / (w0 + (2 + w0 ** 2) ** .5)\n","        #  for s to obtain this formula\n","        coeff = np.sqrt(self.w0 * self.w0 + 2)\n","        return (period * (coeff + self.w0)) / (4.0 * np.pi)\n","\n","    # Frequency representation\n","    def frequency(self, w, s=1.0):\n","        \"\"\"Frequency representation of Morlet.\n","        Parameters\n","        ----------\n","        w : float\n","            Angular frequency. If `s` is not specified, i.e. set to 1,\n","            this can be used as the non-dimensional angular\n","            frequency w * s.\n","        s : float\n","            Scaling factor. Default is 1.\n","        Returns\n","        -------\n","        out : complex\n","            Value of the Morlet wavelet at the given frequency\n","        \"\"\"\n","        x = w * s\n","        # Heaviside mock\n","        Hw = np.array(w)\n","        Hw[w <= 0] = 0\n","        Hw[w > 0] = 1\n","        return np.pi ** -0.25 * Hw * np.exp((-((x - self.w0) ** 2)) / 2)\n","\n","    def coi(self, s):\n","        \"\"\"The e folding time for the autocorrelation of wavelet\n","        power at each scale, i.e. the timescale over which an edge\n","        effect decays by a factor of 1/e^2.\n","        This can be worked out analytically by solving\n","            |Y_0(T)|^2 / |Y_0(0)|^2 = 1 / e^2\n","        \"\"\"\n","        return 2 ** 0.5 * s\n","\n","\n","class Paul(object):\n","    def __init__(self, m=4):\n","        \"\"\"Initialise a Paul wavelet function of order `m`.\"\"\"\n","        self.m = m\n","\n","    def __call__(self, *args, **kwargs):\n","        return self.time(*args, **kwargs)\n","\n","    def time(self, t, s=1.0):\n","        \"\"\"\n","        Complex Paul wavelet, centred at zero.\n","        Parameters\n","        ----------\n","        t : float\n","            Time. If `s` is not specified, i.e. set to 1, this can be\n","            used as the non-dimensional time t/s.\n","        s : float\n","            Scaling factor. Default is 1.\n","        Returns\n","        -------\n","        out : complex\n","            Value of the Paul wavelet at the given time\n","        The Paul wavelet is defined (in time) as::\n","            (2 ** m * i ** m * m!) / (pi * (2 * m)!) \\\n","                    * (1 - i * t / s) ** -(m + 1)\n","        \"\"\"\n","        m = self.m\n","        x = t / s\n","\n","        const = (2 ** m * 1j ** m * factorial(m)) / (np.pi * factorial(2 * m)) ** 0.5\n","        functional_form = (1 - 1j * x) ** -(m + 1)\n","\n","        output = const * functional_form\n","\n","        return output\n","\n","    # Fourier wavelengths\n","    def fourier_period(self, s):\n","        \"\"\"Equivalent Fourier period of Paul\"\"\"\n","        return 4 * np.pi * s / (2 * self.m + 1)\n","\n","    def scale_from_period(self, period):\n","        raise NotImplementedError()\n","\n","    # Frequency representation\n","    def frequency(self, w, s=1.0):\n","        \"\"\"Frequency representation of Paul.\n","        Parameters\n","        ----------\n","        w : float\n","            Angular frequency. If `s` is not specified, i.e. set to 1,\n","            this can be used as the non-dimensional angular\n","            frequency w * s.\n","        s : float\n","            Scaling factor. Default is 1.\n","        Returns\n","        -------\n","        out : complex\n","            Value of the Paul wavelet at the given frequency\n","        \"\"\"\n","        m = self.m\n","        x = w * s\n","        # Heaviside mock\n","        Hw = 0.5 * (np.sign(x) + 1)\n","\n","        # prefactor\n","        const = 2 ** m / (m * factorial(2 * m - 1)) ** 0.5\n","\n","        functional_form = Hw * (x) ** m * np.exp(-x)\n","\n","        output = const * functional_form\n","\n","        return output\n","\n","    def coi(self, s):\n","        \"\"\"The e folding time for the autocorrelation of wavelet\n","        power at each scale, i.e. the timescale over which an edge\n","        effect decays by a factor of 1/e^2.\n","        This can be worked out analytically by solving\n","            |Y_0(T)|^2 / |Y_0(0)|^2 = 1 / e^2\n","        \"\"\"\n","        return s / 2 ** 0.5\n","\n","\n","class DOG(object):\n","    def __init__(self, m=2):\n","        \"\"\"Initialise a Derivative of Gaussian wavelet of order `m`.\"\"\"\n","        if m == 2:\n","            # value of C_d from TC98\n","            self.C_d = 3.541\n","        elif m == 6:\n","            self.C_d = 1.966\n","        else:\n","            pass\n","        self.m = m\n","\n","    def __call__(self, *args, **kwargs):\n","        return self.time(*args, **kwargs)\n","\n","    def time(self, t, s=1.0):\n","        \"\"\"\n","        Return a Derivative of Gaussian wavelet,\n","        When m = 2, this is also known as the \"Mexican hat\", \"Marr\"\n","        or \"Ricker\" wavelet.\n","        It models the function::\n","            ``A d^m/dx^m exp(-x^2 / 2)``,\n","        where ``A = (-1)^(m+1) / (gamma(m + 1/2))^.5``\n","        and   ``x = t / s``.\n","        Note that the energy of the return wavelet is not normalised\n","        according to `s`.\n","        Parameters\n","        ----------\n","        t : float\n","            Time. If `s` is not specified, this can be used as the\n","            non-dimensional time t/s.\n","        s : scalar\n","            Width parameter of the wavelet.\n","        Returns\n","        -------\n","        out : float\n","            Value of the DOG wavelet at the given time\n","        Notes\n","        -----\n","        The derivative of the Gaussian has a polynomial representation:\n","        from http://en.wikipedia.org/wiki/Gaussian_function:\n","        \"Mathematically, the derivatives of the Gaussian function can be\n","        represented using Hermite functions. The n-th derivative of the\n","        Gaussian is the Gaussian function itself multiplied by the n-th\n","        Hermite polynomial, up to scale.\"\n","        http://en.wikipedia.org/wiki/Hermite_polynomial\n","        Here, we want the 'probabilists' Hermite polynomial (He_n),\n","        which is computed by scipy.special.hermitenorm\n","        \"\"\"\n","        x = t / s\n","        m = self.m\n","\n","        # compute the Hermite polynomial (used to evaluate the\n","        # derivative of a Gaussian)\n","        He_n = hermitenorm(m)\n","        # gamma = scipy.special.gamma\n","\n","        const = (-1) ** (m + 1) / gamma(m + 0.5) ** 0.5\n","        function = He_n(x) * np.exp(-(x ** 2) / 2) * np.exp(-1j * x)\n","\n","        return const * function\n","\n","    def fourier_period(self, s):\n","        \"\"\"Equivalent Fourier period of derivative of Gaussian\"\"\"\n","        return 2 * np.pi * s / (self.m + 0.5) ** 0.5\n","\n","    def scale_from_period(self, period):\n","        raise NotImplementedError()\n","\n","    def frequency(self, w, s=1.0):\n","        \"\"\"Frequency representation of derivative of Gaussian.\n","        Parameters\n","        ----------\n","        w : float\n","            Angular frequency. If `s` is not specified, i.e. set to 1,\n","            this can be used as the non-dimensional angular\n","            frequency w * s.\n","        s : float\n","            Scaling factor. Default is 1.\n","        Returns\n","        -------\n","        out : complex\n","            Value of the derivative of Gaussian wavelet at the\n","            given time\n","        \"\"\"\n","        m = self.m\n","        x = s * w\n","        # gamma = scipy.special.gamma\n","        const = -(1j ** m) / gamma(m + 0.5) ** 0.5\n","        function = x ** m * np.exp(-(x ** 2) / 2)\n","        return const * function\n","\n","    def coi(self, s):\n","        \"\"\"The e folding time for the autocorrelation of wavelet\n","        power at each scale, i.e. the timescale over which an edge\n","        effect decays by a factor of 1/e^2.\n","        This can be worked out analytically by solving\n","            |Y_0(T)|^2 / |Y_0(0)|^2 = 1 / e^2\n","        \"\"\"\n","        return 2 ** 0.5 * s\n","\n","\n","class Ricker(DOG):\n","    def __init__(self):\n","        \"\"\"The Ricker, aka Marr / Mexican Hat, wavelet is a\n","        derivative of Gaussian order 2.\n","        \"\"\"\n","        DOG.__init__(self, m=2)\n","        # value of C_d from TC98\n","        self.C_d = 3.541\n","\n","\n","\n","\n","### from https://www.kaggle.com/code/anjum48/continuous-wavelet-transform-cwt-in-pytorch#PyTorch-implementation\n","class CWT2(nn.Module):\n","    def __init__(\n","        self,\n","        dj=0.0625,\n","        dt=1 / 2048,\n","        wavelet=Morlet(),\n","        fmin: int = 20,\n","        fmax: int = 500,\n","        output_format=\"Magnitude\",\n","        trainable=False,\n","        hop_length: int = 1,\n","    ):\n","        super().__init__()\n","        self.wavelet = wavelet\n","\n","        self.dt = dt\n","        self.dj = dj\n","        self.fmin = fmin\n","        self.fmax = fmax\n","        self.output_format = output_format\n","        self.trainable = trainable  # TODO make kernel a trainable parameter\n","        self.stride = (1, hop_length)\n","        # self.padding = 0  # \"same\"\n","\n","        self._scale_minimum = self.compute_minimum_scale()\n","\n","        self.signal_length = None\n","        self._channels = None\n","\n","        self._scales = None\n","        self._kernel = None\n","        self._kernel_real = None\n","        self._kernel_imag = None\n","\n","    def compute_optimal_scales(self):\n","        \"\"\"\n","        Determines the optimal scale distribution (see. Torrence & Combo, Eq. 9-10).\n","        :return: np.ndarray, collection of scales\n","        \"\"\"\n","        if self.signal_length is None:\n","            raise ValueError(\n","                \"Please specify signal_length before computing optimal scales.\"\n","            )\n","        J = int(\n","            (1 / self.dj) * np.log2(self.signal_length * self.dt / self._scale_minimum)\n","        )\n","        scales = self._scale_minimum * 2 ** (self.dj * np.arange(0, J + 1))\n","\n","        # Remove high and low frequencies\n","        frequencies = np.array([1 / self.wavelet.fourier_period(s) for s in scales])\n","        if self.fmin:\n","            frequencies = frequencies[frequencies >= self.fmin]\n","            scales = scales[0 : len(frequencies)]\n","        if self.fmax:\n","            frequencies = frequencies[frequencies <= self.fmax]\n","            scales = scales[len(scales) - len(frequencies) : len(scales)]\n","\n","        return scales\n","\n","    def compute_minimum_scale(self):\n","        \"\"\"\n","        Choose s0 so that the equivalent Fourier period is 2 * dt.\n","        See Torrence & Combo Sections 3f and 3h.\n","        :return: float, minimum scale level\n","        \"\"\"\n","        dt = self.dt\n","\n","        def func_to_solve(s):\n","            return self.wavelet.fourier_period(s) - 2 * dt\n","\n","        return optimize.fsolve(func_to_solve, 1)[0]\n","\n","    def _build_filters(self):\n","        self._filters = []\n","        for scale_idx, scale in enumerate(self._scales):\n","            # Number of points needed to capture wavelet\n","            M = 10 * scale / self.dt\n","            # Times to use, centred at zero\n","            t = torch.arange((-M + 1) / 2.0, (M + 1) / 2.0) * self.dt\n","            if len(t) % 2 == 0:\n","                t = t[0:-1]  # requires odd filter size\n","            # Sample wavelet and normalise\n","            norm = (self.dt / scale) ** 0.5\n","            filter_ = norm * self.wavelet(t, scale)\n","            self._filters.append(torch.conj(torch.flip(filter_, [-1])))\n","\n","        self._pad_filters()\n","\n","    def _pad_filters(self):\n","        filter_len = self._filters[-1].shape[0]\n","        padded_filters = []\n","\n","        for f in self._filters:\n","            pad = (filter_len - f.shape[0]) // 2\n","            padded_filters.append(nn.functional.pad(f, (pad, pad)))\n","\n","        self._filters = padded_filters\n","\n","    def _build_wavelet_bank(self):\n","        \"\"\"This function builds a 2D wavelet filter using wavelets at different scales\n","\n","        Returns:\n","            tensor: Tensor of shape (num_widths, 1, channels, filter_len)\n","        \"\"\"\n","        self._build_filters()\n","        wavelet_bank = torch.stack(self._filters)\n","        wavelet_bank = wavelet_bank.view(\n","            wavelet_bank.shape[0], 1, 1, wavelet_bank.shape[1]\n","        )\n","        # See comment by tez6c32\n","        # https://www.kaggle.com/anjum48/continuous-wavelet-transform-cwt-in-pytorch/comments#1499878\n","        # wavelet_bank = torch.cat([wavelet_bank] * self.channels, 2)\n","        return wavelet_bank\n","\n","    def forward(self, x):\n","        \"\"\"Compute CWT arrays from a batch of multi-channel inputs\n","\n","        Args:\n","            x (torch.tensor): Tensor of shape (batch_size, channels, time)\n","\n","        Returns:\n","            torch.tensor: Tensor of shape (batch_size, channels, widths, time)\n","        \"\"\"\n","        if self.signal_length is None:\n","            self.signal_length = x.shape[-1]\n","            self.channels = x.shape[-2]\n","            self._scales = self.compute_optimal_scales()\n","            self._kernel = self._build_wavelet_bank()\n","\n","            if self._kernel.is_complex():\n","                self._kernel_real = self._kernel.real\n","                self._kernel_imag = self._kernel.imag\n","\n","        x = x.unsqueeze(1)\n","\n","        if self._kernel.is_complex():\n","            if (\n","                x.dtype != self._kernel_real.dtype\n","                or x.device != self._kernel_real.device\n","            ):\n","                self._kernel_real = self._kernel_real.to(device=x.device, dtype=x.dtype)\n","                self._kernel_imag = self._kernel_imag.to(device=x.device, dtype=x.dtype)\n","\n","            # Strides > 1 not yet supported for \"same\" padding\n","            # output_real = nn.functional.conv2d(\n","            #     x, self._kernel_real, padding=self.padding, stride=self.stride\n","            # )\n","            # output_imag = nn.functional.conv2d(\n","            #     x, self._kernel_imag, padding=self.padding, stride=self.stride\n","            # )\n","            output_real = conv2d_same(x, self._kernel_real, stride=self.stride)\n","            output_imag = conv2d_same(x, self._kernel_imag, stride=self.stride)\n","            output_real = torch.transpose(output_real, 1, 2)\n","            output_imag = torch.transpose(output_imag, 1, 2)\n","\n","            if self.output_format == \"Magnitude\":\n","                return torch.sqrt(output_real ** 2 + output_imag ** 2)\n","            else:\n","                return torch.stack([output_real, output_imag], -1)\n","\n","        else:\n","            if x.device != self._kernel.device or x.dtype != self._kernel.dtype:\n","                self._kernel = self._kernel.to(device=x.device, dtype=x.dtype)\n","\n","            # output = nn.functional.conv2d(\n","            #     x, self._kernel, padding=self.padding, stride=self.stride\n","            # )\n","            output = conv2d_same(x, self._kernel, stride=self.stride)\n","            return torch.transpose(output, 1, 2)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Global Variables"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# audio file\n","KAGGLE_TRAIN = '/kaggle/input/birdclef-2024/train_audio'\n","ADDED_TRAIN = '/kaggle/input/birdclef2024-additional-mp3/additional_audio'\n","ADDED_TRAIN_1 = '/kaggle/input/birdclef2024-additional-wav-1/additional_audio-1'\n","ADDED_TRAIN_2 = '/kaggle/input/birdclef2024-additional-wav-2/additional_audio-2'\n","TEST_SOUNDSCAPE = CFG.TEST_SOUNDSCAPE\n","os.makedirs(KAGGLE_TRAIN, exist_ok=True)\n","\n","# to save image from audio\n","SAVE_TRAIN = '/kaggle/working/train_image'\n","SAVE_TEST = '/kaggle/working/test_image'\n","\n","# image input\n","TRAIN_IMAGE = Path('/kaggle/input/bird2024-spec-v6/train_image/spec')\n","TEST_IMAGE = Path('/kaggle/working/test_image/spec')\n","\n","# model trained\n","TRAINED_MODEL = Path('/kaggle/input/birdcref-2024-introduction-withtraining-train-v2')\n"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T02:40:59.686902Z","iopub.status.busy":"2024-06-09T02:40:59.686318Z","iopub.status.idle":"2024-06-09T02:41:31.839987Z","shell.execute_reply":"2024-06-09T02:41:31.837469Z","shell.execute_reply.started":"2024-06-09T02:40:59.686864Z"},"trusted":true},"outputs":[],"source":["class preprocessing():\n","    def __init__(self, AUDIO_DIRECTORY, SAVE_DIRECTORY, view=CFG.VIEW, view_raw=CFG.VIEW_RAW, test=CFG.test):\n","        # config\n","        self.AUDIO_DIRECTORY = AUDIO_DIRECTORY\n","        self.SAVE_DIRECTORY = SAVE_DIRECTORY\n","        self.view = view\n","        self.view_raw = view_raw\n","        self.test = test\n","        \n","        # make directory\n","        make_directory = True\n","        if make_directory:\n","            func_names = [method for method in dir(self) if callable(getattr(self, method)) and method.startswith(\"func\")]\n","            print(func_names)\n","            os.makedirs(self.SAVE_DIRECTORY, exist_ok=True)\n","            for func_name in func_names:\n","                func = func_name.split('_')[-1]\n","                os.makedirs(self.SAVE_DIRECTORY + '/' + func, exist_ok=True)\n","    \n","    def load_wave(self, audio_filepath, offset=0, duration=5, desired_length=960000)\n","        # load audio\n","        self.y, _ = librosa.load(audio_filepath, sr=CFG.SR , offset=offset, duration=30)\n","        while self.y.shape[0] < desired_length:\n","            self.y = np.concatenate((self.y, self.y))\n","            if self.y.shape[0] > desired_length:\n","                self.y = self.y[:desired_length]\n","        self.sr = CFG.SR\n","    \n","    def normalize(self, data: np.ndarray):\n","        if data.dtype == np.uint8 and data.min() >= 0 and data.max() <= 255:\n","            return data\n","        data = data.astype(np.single)\n","        # Normalize 0 to min\n","        data = data - data.min()\n","        # Normalize 0 to 255\n","        data = (data / data.max() * 255).astype(np.uint8)\n","        \n","        return data\n","    \n","    # apply procesing with save\n","    def apply_func(self, function):\n","        \n","        # get the type of processing\n","        species_list = os.listdir(self.AUDIO_DIRECTORY)\n","        \n","        # when train\n","        if not self.test:\n","            \n","            for species in species_list:\n","                species_path = self.AUDIO_DIRECTORY + '/' + species\n","                audio_file_list = os.listdir(species_path)\n","                \n","                for audio_count, audio_file in enumerate(audio_file_list):\n","                    audio_filepath = species_path + '/' + audio_file\n","                    n_load = int(CFG.DURATION/CFG.LENGTH)\n","                    \n","                    for i in range(n_load):\n","                        # load audio\n","                        self.load_wave(audio_filepath, offset=int(i*CFG.LENGTH), duration=CFG.LENGTH) \n","                        # apply function\n","                        output = function() \n","                        output = self.normalize(output)\n","\n","                        SAVE_DIRECTORY = Path(self.SAVE_DIRECTORY + '/second_30')\n","                        SAVE_DIRECTORY.mkdir(exist_ok=True)\n","                        SAVE_PATH = SAVE_DIRECTORY / f\"{audio_file.split('.')[0]}.npy\"\n","                        # save as pickle with gzip\n","                        self.save_as_pickle_gzip(output, SAVE_PATH)\n","                        del output\n","                        \n","                    if CFG.ONLY_ONCE:\n","                        break\n","                if CFG.ONLY_ONCE:\n","                    break\n","        \n","        # when test\n","        if self.test:\n","            audio_directory_path = self.AUDIO_DIRECTORY\n","            audio_length = int(4*60) # second\n","            audio_offset_unit_max = int(audio_length / 5)\n","            for audio_file_path in audio_directory_path.glob('*.ogg'):\n","                    for audio_offset_unit in range(audio_offset_unit_max):\n","                        audio_offset = audio_offset_unit * 5       \n","                        # load audio                 \n","                        self.load_wave(str(audio_file_path), audio_offset) \n","                        # apply function\n","                        output = function() \n","                        output = self.normalize(output)\n","                        \n","                        # save\n","                        SAVE_DIRECTORY = Path(self.SAVE_DIRECTORY) / function.__name__.split('_')[-1]\n","                        SAVE_DIRECTORY.mkdir(exist_ok=True)\n","                        if CFG.NO_SOUNDSCAPE:\n","                            SAVE_PATH = SAVE_DIRECTORY  / f\"{audio_file_path.stem.replace('XC','')}_{audio_offset+5}.npy\" # [soundscape_id]_[end_time].npy\n","                        else:\n","                            SAVE_PATH = SAVE_DIRECTORY  / f\"{audio_file_path.stem.replace('soundscape_','')}_{audio_offset+5}.npy\" # [soundscape_id]_[end_time].npy\n","                        np.save(SAVE_PATH, output)\n","                        del output\n","                        \n","                        \n","                        if CFG.ONLY_ONCE:\n","                            break\n","                    if CFG.ONLY_ONCE:\n","                        break\n","          \n","        \n","    def save_as_pickle_gzip(self, data, filepath):       \n","        with gzip.open(str(filepath) + '.gz', 'wb') as f:\n","            pickle.dump(data, f)\n","            \n","    \n","    # as is\n","    def func_waveform(self):\n","        if self.view:\n","            print('waveform shape: ', self.y.shape)\n","            print('waveform type: ', type(self.y))\n","            print('waveform value type: ', type(self.y[0]))\n","            print('waveform shape type: ', type(self.y.shape))\n","            print('waveform shape value type: ', type(self.y.shape[0]))\n","            display(Audio(self.y, rate=self.sr))\n","            plt.figure(figsize=(10, 4))\n","            librosa.display.waveshow(self.y, sr=self.sr)\n","            plt.title('Waveform')\n","            plt.xlabel('Time (s)')\n","            plt.ylabel('Amplitude')\n","            plt.show()\n","        return self.y\n","    \n","    # spectrogram\n","    def func_spec(self):\n","        spec = librosa.amplitude_to_db(np.abs(librosa.stft(self.y)), ref=np.max)\n","        min_ = spec.min()\n","        max_ = spec.max()\n","        if max_ != min_:\n","            spec = (spec - min_)/(max_ - min_)\n","        \n","        if self.view:\n","            print('spec shape: ', spec.shape)\n","            plt.figure(figsize=(10, 4))\n","            librosa.display.specshow(spec, sr=self.sr, x_axis='time', y_axis='log')\n","            plt.colorbar(format='%+2.0f dB')\n","            plt.title('Spectrogram')\n","            plt.show()\n","            \n","        return spec\n","    \n","    # melspectrogram\n","    def func_melspec(self, normalization=False):\n","        melspec = librosa.feature.melspectrogram(\n","            y=self.y, \n","            sr=CFG.SR,                  # sample rate\n","            n_fft=CFG.N_FFT,            # number of samples in window \n","            hop_length=CFG.HOP_LENGTH,  # step size of window\n","            n_mels=CFG.MELSPEC_H,       # horizontal resolution from fmin→fmax in log scale\n","            fmin=CFG.fmin,                    # minimum frequency\n","            fmax=CFG.fmax,                 # maximum frequency\n","            power=2.0,                  # intensity^power for log scale\n","        )\n","        melspec = librosa.power_to_db(melspec, ref=np.max)\n","        \n","        if self.view:\n","            print('melspec shape: ', melspec.shape)\n","            plt.figure(figsize=(10, 4))\n","            librosa.display.specshow(melspec, sr=self.sr, x_axis='time', y_axis='mel')\n","            plt.colorbar(format='%+2.0f dB')\n","            plt.title('Mel Spectrogram')\n","            plt.show()\n","            \n","        return melspec\n","    \n","    # scalogram\n","    def func_scalogram(self):\n","\n","        sig_pt = torch.tensor(self.normalize(self.y), dtype=torch.float32)\n","        sig_pt = torch.stack([sig_pt] * 1)  # 3 channels\n","        sig_pt = torch.stack([sig_pt] * 1)  # Batch size of 32\n","\n","        pycwt = CWT2(dt=1/1000)\n","        start =  time()\n","        out = pycwt(sig_pt)\n","        end = time()\n","        \n","        if self.view:\n","            print('scarogram shape: ', out.shape)\n","            plt.figure(figsize=(10, 4))\n","            plt.imshow(abs(out[0,0]), aspect='auto', extent=[0, len(self.y) / self.sr, 1, 100], cmap='jet', origin='lower')\n","            plt.colorbar()\n","            plt.title('Scalogram')\n","            plt.xlabel('Time (s)')\n","            plt.ylabel('Scale')\n","\n","        return abs(out[0, 0].to('cpu').detach().numpy().copy())\n","\n","    # chromagram\n","    def func_chromagram(self):\n","        C = librosa.feature.chroma_cqt(y=self.y, sr=self.sr)\n","        \n","        if self.view:\n","            print('chromagram shape: ', C.shape)\n","            plt.figure(figsize=(10, 4))\n","            librosa.display.specshow(C, sr=self.sr, x_axis='time', y_axis='chroma', cmap='coolwarm')\n","            plt.colorbar()\n","            plt.title('Chromagram')\n","            plt.show()\n","            \n","        return C\n","\n","    # Mel-Frequency Cepstral Coefficients(mfcc)\n","    def func_mfcc(self): \n","        mfcc = librosa.feature.mfcc(y=self.y, sr=self.sr)\n","        \n","        if self.view:\n","            print('mfcc shape: ', mfcc.shape)\n","            plt.figure(figsize=(10, 4))\n","            librosa.display.specshow(mfcc, sr=self.sr, x_axis='time')\n","            plt.ylabel('MFCC coeffs')\n","            plt.colorbar()\n","            plt.title('MFCC')\n","            plt.show()\n","            \n","        return mfcc\n","\n","    # spectral contrast\n","    def func_spectralcontrast(self):\n","        contrast = librosa.feature.spectral_contrast(y=self.y, sr=self.sr)\n","        \n","        if self.view:\n","            print('contrast shape: ', contrast.shape)\n","            plt.figure(figsize=(10, 4))\n","            librosa.display.specshow(contrast, x_axis='time')\n","            plt.colorbar()\n","            plt.ylabel('Frequency bands')\n","            plt.title('Spectral Contrast')\n","            plt.show()\n","            \n","        return contrast\n","    \n","    # melspec at top and scalo at under\n","    def func_melspecscalo(self):\n","        melspec = self.func_melspec()\n","        melspec = self.normalize(melspec)\n","        \n","        scalo = self.func_scalogram()\n","        scalo = self.normalize(scalo)\n","        size_align = (int(62.6*CFG.LENGTH), 128)\n","        scalo = cv2.resize(scalo, size_align, interpolation=cv2.INTER_AREA)\n","        \n","        melspec_scalo = np.concatenate([melspec, scalo], axis=0)\n","\n","        return melspec_scalo\n","    \n","    \n","    def execute(self):\n","        # select the processing\n","        func_list = [\n","            self.func_waveform,\n","#             self.func_spec,\n","#             self.func_melspec,\n","#             self.func_scalogram,\n","#             self.func_chromagram,\n","#             self.func_mfcc,\n","#             self.func_spectralcontrast,\n","#             self.func_melspecscalo,\n","        ]\n","        for func in func_list:\n","            self.apply_func(func)\n","\n","# ・ Define preprocessing class\n","preprocessing_kaggle = preprocessing(KAGGLE_TRAIN, SAVE_TRAIN)\n","# preprocessing_added_train = preprocessing(ADDED_TRAIN, SAVE_TRAIN)\n","# preprocessing_added_train_1 = preprocessing(ADDED_TRAIN_1, SAVE_TRAIN)\n","# preprocessing_added_train_2 = preprocessing(ADDED_TRAIN_2, SAVE_TRAIN)\n","# preprocessing_test = preprocessing(TEST_SOUNDSCAPE, SAVE_TEST)\n","\n","t1 = time()\n","# ・ Execute preprocessing\n","preprocessing_kaggle.execute()\n","# preprocessing_added_train.execute()\n","# preprocessing_added_train_1.execute()\n","# preprocessing_added_train_2.execute()\n","# preprocessing_test.execute()\n","t2 = time()\n","print('Preprocessing time: ', f\"{(t2-t1)/60}m\")"]},{"cell_type":"markdown","metadata":{},"source":["END"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":8068726,"sourceId":70203,"sourceType":"competition"},{"datasetId":4745108,"sourceId":8048860,"sourceType":"datasetVersion"},{"datasetId":4746211,"sourceId":8048895,"sourceType":"datasetVersion"},{"datasetId":4746338,"sourceId":8048897,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}
